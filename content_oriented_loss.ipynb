{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentOrientedDataset(Dataset):\n",
    "    def __init__(self, root='', crop_size=256, \n",
    "        normalize=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = root \n",
    "        img_extensions = ['.jpg', '.png']\n",
    "        self.imgs = []\n",
    "        for ext in img_extensions:\n",
    "            self.imgs += glob.glob(os.path.join(self.data_dir, f'images/**/*{ext}'), recursive=True)\n",
    "        self.crop_size = crop_size\n",
    "        self.image_dims = (3, self.crop_size, self.crop_size)\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        json_file_path = os.path.join(self.data_dir, \"face_coords.json\")\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            self.face_coords = json.load(json_file)\n",
    "\n",
    "    def _augment(self, img, face_masks, structure_masks):\n",
    "        \"\"\"\n",
    "        Apply augmentations \n",
    "        \"\"\"\n",
    "        SCALE_MIN = 0.75\n",
    "        SCALE_MAX = 0.95\n",
    "        H, W, _ = img.shape # slightly confusing\n",
    "        shortest_side_length = min(H,W)\n",
    "        minimum_scale_factor = float(self.crop_size) / float(shortest_side_length)\n",
    "        scale_low = max(minimum_scale_factor, SCALE_MIN)\n",
    "        scale_high = max(scale_low, SCALE_MAX)\n",
    "        scale = np.random.uniform(scale_low, scale_high)\n",
    "\n",
    "        self.augmentations = iaa.Sequential([iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "                                             iaa.Resize((math.ceil(scale * H), math.ceil(scale * W))), # resize\n",
    "                                             iaa.size.CropToFixedSize(self.crop_size,self.crop_size)])\n",
    "        \n",
    "        masks = np.dstack( [face_masks, structure_masks])\n",
    "        masks = SegmentationMapsOnImage(masks, shape=(H,W,2))\n",
    "        img, masks = self.augmentations(image=img, segmentation_maps=masks)\n",
    "        masks = masks.get_arr()\n",
    "        face_masks, structure_masks = masks[:,:,0], masks[:,:,1]\n",
    "        \n",
    "        return img, face_masks, structure_masks\n",
    "\n",
    "    def _transforms(self, img, face_mask, structure_mask):\n",
    "        pass\n",
    "    \n",
    "    def get_face_mask(self, idx, shape): \n",
    "        pass\n",
    "\n",
    "    def get_structure_mask(self, idx):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
