{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import ContentOrientedDataset\n",
    "from loss import ContentOrientedLoss\n",
    "from model import DummyModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "import tqdm\n",
    "\n",
    "def display_images_with_titles(images, titles):\n",
    "    num_images = len(images)\n",
    "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        axs[i].imshow(images[i].permute(1, 2, 0).numpy())  \n",
    "        axs[i].set_title(titles[i])  \n",
    "        axs[i].axis('off')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset loads the images and the raw face and structure masks from the disk. If the face coords and structure masks are not available then it automatically generates them when being initialised. With raw masks I mean the masks without the priority criteria mentionned in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_411309/2594557043.py:8: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "dataset = ContentOrientedDataset(root='dataset', crop_size=256, normalize=False)\n",
    "[img, unproc_face_mask, unproc_structure_mask], bpp = dataset[0]\n",
    "display_images_with_titles([img, unproc_face_mask, unproc_structure_mask], [\"image\", \"unprocessed_face_mask\", \"unprocessed_structure_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks are processed to conform with the priority criteria directly when the loss is computed and the texture mask is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/TUEIEDAprojects/SystemDesign/work/anomaly_detect/anaconda3/envs/hific/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/nfs/TUEIEDAprojects/SystemDesign/work/anomaly_detect/anaconda3/envs/hific/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/ge95jud/GLeaD_HiFiC/src/loss/perceptual_similarity/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_411309/2594557043.py:8: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "model = DummyModel()\n",
    "args = namedtuple(\"LossArgs\", [\"alpha\", \"beta\", \"delta\", \"epsilon\", \"gamma\", \"normalize_input_image\", \"gan_loss_type\"])\n",
    "args.alpha, args.beta, args.delta, args.epsilon, args.gamma = 0.01, 1, 0.0005, 0.3, 0.2\n",
    "args.normalize_input_image, args.gan_loss_type = False, \"non_saturating\"\n",
    "loss = ContentOrientedLoss(args, discriminator=model.discriminator)\n",
    "processed_face_mask, processed_structure_mask, processed_texture_mask = loss.process_masks(unproc_face_mask, unproc_structure_mask)\n",
    "display_images_with_titles([img, processed_face_mask, processed_structure_mask, processed_texture_mask], [\"image\", \"processed_face_mask\", \"processed_structure_mask\", \"processed_texture_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop is split into two phases. In the first phase only the encoder/decoder are optimized. In the second stage only the discriminator is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = DataLoader(dataset, batch_size=4)\n",
    "optimizer_encoder = torch.optim.Adam(model.encoder.parameters(), lr=1e-4)\n",
    "optimizer_decoder = torch.optim.Adam(model.decoder.parameters(), lr=1e-4)\n",
    "optimizer_discriminator = torch.optim.Adam(model.discriminator.parameters(), lr=1e-4)\n",
    "model = model.to(device)\n",
    "phase = \"ED\"\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    for [orig_imgs, face_masks, structure_masks], bpp in dataloader:\n",
    "        orig_imgs, face_masks, structure_masks = orig_imgs.to(device), face_masks.to(device), structure_masks.to(device)\n",
    "        recon_imgs = model(orig_imgs)\n",
    "        compression_loss, D_loss = loss(orig_imgs, recon_imgs, face_masks, structure_masks)\n",
    "        if phase==\"ED\":\n",
    "            compression_loss.backward()\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "            phase = \"D\"\n",
    "        else: \n",
    "            D_loss.backward()\n",
    "            optimizer_discriminator.step()\n",
    "            optimizer_discriminator.zero_grad()\n",
    "            phase = \"ED\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hific",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
